#!/usr/bin/env python3
"""
Production Demo Script
This script demonstrates:
1. Reading YAML configuration files
2. Processing and writing data
3. Moving files to Desktop
4. Production-ready error handling and logging
"""

import yaml
import json
import os
import shutil
import time
import sys
from pathlib import Path
from datetime import datetime
import logging


def setup_logging():
    """Setup logging configuration"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)


def get_desktop_path():
    """Get the Desktop path for the current user"""
    home = Path.home()
    desktop_path = home / "Desktop"

    # Create Desktop directory if it doesn't exist
    desktop_path.mkdir(exist_ok=True)
    return desktop_path


def read_yaml_config(config_path):
    """Read YAML configuration file"""
    try:
        with open(config_path, 'r', encoding='utf-8') as file:
            config = yaml.safe_load(file)
        return config
    except FileNotFoundError:
        # Create a default config if file doesn't exist
        default_config = {
            'application': {
                'name': 'Production Demo',
                'version': '1.0.0',
                'environment': 'production'
            },
            'data': {
                'input_files': ['data1.txt', 'data2.txt'],
                'output_format': 'json',
                'processing_delay': 2
            },
            'files': {
                'move_to_desktop': True,
                'backup_original': True
            }
        }

        with open(config_path, 'w', encoding='utf-8') as file:
            yaml.dump(default_config, file, default_flow_style=False)

        return default_config
    except yaml.YAMLError as e:
        raise Exception(f"Error parsing YAML file: {e}")


def read_txt_files(script_dir, logger):
    """Read all .txt files in the script directory"""
    txt_files = []
    txt_contents = {}

    for txt_file in script_dir.glob("*.txt"):
        if txt_file.name != "time.txt":  # Skip time.txt if it already exists
            try:
                with open(txt_file, 'r', encoding='utf-8') as file:
                    content = file.read()
                    txt_contents[txt_file.name] = content
                    txt_files.append(txt_file.name)
                    logger.info(f"Read txt file: {txt_file.name} ({len(content)} characters)")
            except Exception as e:
                logger.error(f"Error reading {txt_file.name}: {e}")

    return txt_files, txt_contents


def write_time_file(script_dir, logger):
    """Write current time to time.txt"""
    current_time = datetime.now()
    time_content = f"""Current Time Information
======================
Date: {current_time.strftime('%Y-%m-%d')}
Time: {current_time.strftime('%H:%M:%S')}
Timestamp: {current_time.isoformat()}
Unix Timestamp: {int(current_time.timestamp())}
Timezone: {current_time.astimezone().tzname()}

Generated by Production Demo Script
"""

    time_file_path = script_dir / "time.txt"

    try:
        with open(time_file_path, 'w', encoding='utf-8') as file:
            file.write(time_content)
        logger.info(f"Created time.txt with current time: {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
        return time_file_path
    except Exception as e:
        logger.error(f"Error writing time.txt: {e}")
        return None


def process_data(config, logger, script_dir):
    """Process data based on configuration"""
    logger.info("Starting data processing...")

    # Read txt files
    txt_files, txt_contents = read_txt_files(script_dir, logger)

    # Simulate processing delay
    delay = config.get('data', {}).get('processing_delay', 1)
    time.sleep(delay)

    # Generate processed data
    processed_data = {
        'timestamp': datetime.now().isoformat(),
        'application': config.get('application', {}),
        'status': 'completed',
        'txt_files_read': txt_files,
        'txt_file_contents': txt_contents,
        'processing_summary': {
            'txt_files_found': len(txt_files),
            'total_characters_read': sum(len(content) for content in txt_contents.values()),
            'processing_time': delay
        }
    }

    logger.info(f"Processed {len(txt_files)} txt files successfully")
    return processed_data


def write_output_data(data, output_path, format_type='json'):
    """Write processed data to output file"""
    if format_type.lower() == 'json':
        with open(output_path, 'w', encoding='utf-8') as file:
            json.dump(data, file, indent=2, ensure_ascii=False)
    elif format_type.lower() == 'yaml':
        with open(output_path, 'w', encoding='utf-8') as file:
            yaml.dump(data, file, default_flow_style=False)
    else:
        raise ValueError(f"Unsupported output format: {format_type}")


def move_file_to_desktop(source_path, desktop_path, logger, backup=True):
    """Move file to Desktop with optional backup"""
    try:
        source = Path(source_path)
        if not source.exists():
            logger.warning(f"Source file does not exist: {source_path}")
            return False

        # Create backup if requested
        if backup:
            backup_name = f"{source.stem}_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}{source.suffix}"
            backup_path = source.parent / backup_name
            shutil.copy2(source, backup_path)
            logger.info(f"Created backup: {backup_path}")

        # Move file to Desktop
        destination = desktop_path / source.name

        # Handle existing files
        if destination.exists():
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            destination = desktop_path / f"{source.stem}_{timestamp}{source.suffix}"

        shutil.move(str(source), str(destination))
        logger.info(f"Moved file to Desktop: {destination}")
        return True

    except Exception as e:
        logger.error(f"Error moving file to Desktop: {e}")
        return False


def main():
    """Main execution function"""
    logger = setup_logging()

    try:
        logger.info("=== Production Demo Script Started ===")

        # Define paths
        script_dir = Path(__file__).parent
        config_path = script_dir / "production_config.yaml"

        # Step 1: Read YAML configuration
        logger.info("Reading YAML configuration...")
        config = read_yaml_config(config_path)
        logger.info(f"Configuration loaded: {config.get('application', {}).get('name', 'Unknown')}")

        # Step 2: Process data (read txt files)
        logger.info("Processing data...")
        processed_data = process_data(config, logger, script_dir)

        # Step 3: Write current time to time.txt
        logger.info("Writing current time to time.txt...")
        time_file_path = write_time_file(script_dir, logger)

        # # Step 4: Write output data
        # output_format = config.get('data', {}).get('output_format', 'json')
        # output_filename = f"production_output_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{output_format}"
        # output_path = script_dir / output_filename

        # logger.info(f"Writing output data to: {output_path}")
        # write_output_data(processed_data, output_path, output_format)

        # Step 5: Move files to Desktop
        desktop_path = get_desktop_path()
        logger.info(f"Desktop path: {desktop_path}")

        files_moved = 0

        # Always move time.txt to Desktop
        if time_file_path and time_file_path.exists():
            if move_file_to_desktop(time_file_path, desktop_path, logger, backup=False):
                files_moved += 1

        # Step 6: Final status report
        final_report = {
            'status': 'SUCCESS',
            'timestamp': datetime.now().isoformat(),
            'files_moved': files_moved,
            'txt_files_processed': len(processed_data.get('txt_files_read', [])),
            'time_file_created': time_file_path is not None,
            'processing_completed': True
        }

        logger.info("=== Production Demo Script Completed Successfully ===")
        print(json.dumps(final_report), flush=True)

        return 0

    except Exception as e:
        error_report = {
            'status': 'ERROR',
            'timestamp': datetime.now().isoformat(),
            'error_message': str(e),
            'processing_completed': False
        }

        logger.error(f"Script failed with error: {e}")
        print(json.dumps(error_report), flush=True)
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
